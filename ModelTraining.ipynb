{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 8000\n",
      "Validation set size: 1000\n",
      "Test set size: 1000\n",
      "Shape of training set: (8000, 14, 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "408d38b5b29b4bd7a01a71e5ee78e89e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel Means:  tensor([72.0667, 81.2554, 67.7689])\n",
      "Channel Standard Deviations:  tensor([65.6007, 64.9408, 62.9515])\n",
      "Joint Coordinate Means:  tensor([82.2304, 82.2798])\n",
      "Joint Coordinate Std:  tensor([70.2122, 70.1325])\n"
     ]
    }
   ],
   "source": [
    "from LSPDataset import LSPDataset\n",
    "from LSPTransforms import LSPTransforms\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from utils import display_image_with_pose\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "\n",
    "mats = loadmat(\"lsp/joints.mat\")\n",
    "mats = np.array(mats[\"joints\"])\n",
    "joints = mats.transpose(2, 0, 1)\n",
    "\n",
    "train_size = 0.8\n",
    "val_size = 0.1\n",
    "test_size = 0.1\n",
    "\n",
    "\n",
    "# create training, validation and test sets\n",
    "indices = range(len(joints))\n",
    "indices = np.random.permutation(indices)\n",
    "\n",
    "train_indices = indices[: int(train_size * len(joints))]\n",
    "val_indices = indices[\n",
    "    int(train_size * len(joints)) : int((train_size + val_size) * len(joints))\n",
    "]\n",
    "test_indices = indices[int((train_size + val_size) * len(joints)) :]\n",
    "\n",
    "print(f\"Training set size: {len(train_indices)}\")\n",
    "print(f\"Validation set size: {len(val_indices)}\")\n",
    "print(f\"Test set size: {len(test_indices)}\")\n",
    "\n",
    "# filter the joints matrix to only include train_indices\n",
    "train_joints = joints[train_indices]\n",
    "print(f\"Shape of training set: {train_joints.shape}\")\n",
    "\n",
    "# create dataset and calculate mean and std for image and joints\n",
    "\n",
    "train_dummy = LSPDataset(\n",
    "    image_path=\"lsp/images\",\n",
    "    image_indexes=train_indices,\n",
    "    joints_path=\"lsp/joints.mat\",\n",
    "    joints_indexes=train_indices,\n",
    "    transforms=LSPTransforms(220),\n",
    ")\n",
    "train_dummy_loader = DataLoader(\n",
    "    train_dummy, batch_size=64, shuffle=False, num_workers=0\n",
    ")\n",
    "\n",
    "image_mean = torch.zeros(3)\n",
    "image_std = torch.zeros(3)\n",
    "joint_mean = torch.zeros(2)\n",
    "joint_std = torch.zeros(2)\n",
    "n = 0\n",
    "\n",
    "for image, joints, _ in tqdm(train_dummy_loader):\n",
    "    # calculate image mean and std\n",
    "    batch_size = image.size(0)\n",
    "    image = image.view(batch_size, 3, -1)  # Reshape to (batch_size, 3, height*width)\n",
    "    image_mean += image.mean(2).sum(0)  # Sum of means for each channel\n",
    "    image_std += image.std(2).sum(0)  # Sum of std deviations for each channel\n",
    "\n",
    "    # calculate joint mean and std\n",
    "    joints = joints[:, :, :2]\n",
    "    joint_mean += joints.mean(1).sum(0)  # Sum of means for each coordinate\n",
    "    joint_std += joints.std(1).sum(0)  # Sum of std deviations for each coordinate\n",
    "\n",
    "    n += batch_size\n",
    "\n",
    "\n",
    "# Calculate the mean and standard deviation across all images\n",
    "image_mean /= n\n",
    "image_std /= n\n",
    "\n",
    "print(\"Channel Means: \", image_mean)\n",
    "print(\"Channel Standard Deviations: \", image_std)\n",
    "\n",
    "\n",
    "# Calculate the mean and standard deviation across all joints\n",
    "joint_mean /= n\n",
    "joint_std /= n\n",
    "\n",
    "print(\"Joint Coordinate Means: \", joint_mean)\n",
    "print(\"Joint Coordinate Std: \", joint_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the datasets\n",
    "\n",
    "IMAGE_SIZE = 220\n",
    "JOINT_DIR = \"lsp/joints.mat\"\n",
    "IMAGE_DIR = \"lsp/images\"\n",
    "\n",
    "train = LSPDataset(\n",
    "    image_path=IMAGE_DIR,\n",
    "    image_indexes=train_indices,\n",
    "    joints_path=JOINT_DIR,\n",
    "    joints_indexes=train_indices,\n",
    "    transforms=LSPTransforms(\n",
    "        IMAGE_SIZE,\n",
    "        image_mean.numpy(),\n",
    "        image_std.numpy(),\n",
    "        joint_mean.numpy(),\n",
    "        joint_std.numpy(),\n",
    "    ),\n",
    ")\n",
    "\n",
    "test = LSPDataset(\n",
    "    image_path=IMAGE_DIR,\n",
    "    image_indexes=test_indices,\n",
    "    joints_path=JOINT_DIR,\n",
    "    joints_indexes=test_indices,\n",
    "    transforms=LSPTransforms(\n",
    "        IMAGE_SIZE,\n",
    "        image_mean.numpy(),\n",
    "        image_std.numpy(),\n",
    "        joint_mean.numpy(),\n",
    "        joint_std.numpy(),\n",
    "    ),\n",
    ")\n",
    "\n",
    "val = LSPDataset(\n",
    "    image_path=IMAGE_DIR,\n",
    "    image_indexes=val_indices,\n",
    "    joints_path=JOINT_DIR,\n",
    "    joints_indexes=val_indices,\n",
    "    transforms=LSPTransforms(\n",
    "        IMAGE_SIZE,\n",
    "        image_mean.numpy(),\n",
    "        image_std.numpy(),\n",
    "        joint_mean.numpy(),\n",
    "        joint_std.numpy(),\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=1, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test, batch_size=1, shuffle=False, num_workers=0)\n",
    "val_loader = DataLoader(val, batch_size=1, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_mse_loss(output, target):\n",
    "    target_coords = target[:, :, :2]\n",
    "    target_mask = target[:, :, 2]\n",
    "    target_mask = target_mask.unsqueeze(-1)\n",
    "    # Reshape output to match target_coords shape\n",
    "    output = output.view(target_coords.shape)\n",
    "\n",
    "    error = (output - target_coords) ** 2\n",
    "    print(\"error\")\n",
    "    print(error)\n",
    "    masked_square_error = error * target_mask\n",
    "    print(\"masked_square_error\")\n",
    "    print(masked_square_error)\n",
    "    loss = masked_square_error.sum() / target_mask.sum()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 96, 53, 53]          34,944\n",
      "       BatchNorm2d-2           [-1, 96, 53, 53]             192\n",
      "              ReLU-3           [-1, 96, 53, 53]               0\n",
      "         MaxPool2d-4           [-1, 96, 26, 26]               0\n",
      "            Conv2d-5          [-1, 256, 26, 26]         614,656\n",
      "       BatchNorm2d-6          [-1, 256, 26, 26]             512\n",
      "              ReLU-7          [-1, 256, 26, 26]               0\n",
      "         MaxPool2d-8          [-1, 256, 12, 12]               0\n",
      "            Conv2d-9          [-1, 384, 12, 12]         885,120\n",
      "      BatchNorm2d-10          [-1, 384, 12, 12]             768\n",
      "             ReLU-11          [-1, 384, 12, 12]               0\n",
      "           Conv2d-12          [-1, 384, 12, 12]       1,327,488\n",
      "      BatchNorm2d-13          [-1, 384, 12, 12]             768\n",
      "             ReLU-14          [-1, 384, 12, 12]               0\n",
      "           Conv2d-15          [-1, 256, 12, 12]         884,992\n",
      "      BatchNorm2d-16          [-1, 256, 12, 12]             512\n",
      "             ReLU-17          [-1, 256, 12, 12]               0\n",
      "        MaxPool2d-18            [-1, 256, 5, 5]               0\n",
      "           Linear-19                 [-1, 4096]      26,218,496\n",
      "      BatchNorm1d-20                 [-1, 4096]           8,192\n",
      "             ReLU-21                 [-1, 4096]               0\n",
      "          Dropout-22                 [-1, 4096]               0\n",
      "           Linear-23                 [-1, 4096]      16,781,312\n",
      "      BatchNorm1d-24                 [-1, 4096]           8,192\n",
      "             ReLU-25                 [-1, 4096]               0\n",
      "          Dropout-26                 [-1, 4096]               0\n",
      "           Linear-27                   [-1, 28]         114,716\n",
      "================================================================\n",
      "Total params: 46,880,860\n",
      "Trainable params: 46,880,860\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.55\n",
      "Forward/backward pass size (MB): 14.58\n",
      "Params size (MB): 178.84\n",
      "Estimated Total Size (MB): 193.97\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from ConvNet import ConvNet\n",
    "import torch.nn as nn\n",
    "import torchsummary\n",
    "\n",
    "model = ConvNet(dropout=0.6, batchnorm=True)\n",
    "\n",
    "torchsummary.summary(model, input_size=(3, 220, 220))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m flattened_joints \u001b[38;5;241m=\u001b[39m joints[:, :\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m      3\u001b[0m mask \u001b[38;5;241m=\u001b[39m joints[:, \u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m----> 5\u001b[0m \u001b[43mmasked_mse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflattened_joints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoints\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m, in \u001b[0;36mmasked_mse_loss\u001b[0;34m(output, target)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmasked_mse_loss\u001b[39m(output, target):\n\u001b[0;32m----> 2\u001b[0m     target_coords \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      3\u001b[0m     target_mask \u001b[38;5;241m=\u001b[39m target[:, :, \u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m      4\u001b[0m     target_mask \u001b[38;5;241m=\u001b[39m target_mask\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 2"
     ]
    }
   ],
   "source": [
    "image, joints, _ = train[0]\n",
    "flattened_joints = joints[:, :2].flatten()\n",
    "mask = joints[:, 2]\n",
    "\n",
    "masked_mse_loss(flattened_joints, joints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n",
      "tensor([[[2.4633e-01, 9.2474e-02],\n",
      "         [4.0198e-02, 9.5143e-02],\n",
      "         [8.5194e-01, 5.9714e-02],\n",
      "         ...,\n",
      "         [2.6365e-02, 6.3627e-02],\n",
      "         [1.5891e+01, 6.8466e+00],\n",
      "         [1.9050e-01, 1.1751e+00]],\n",
      "\n",
      "        [[1.5283e-01, 1.2459e-03],\n",
      "         [2.5769e-01, 2.4223e-04],\n",
      "         [4.5663e-01, 3.0939e-01],\n",
      "         ...,\n",
      "         [2.6249e-01, 5.8232e-01],\n",
      "         [6.8496e+00, 1.0871e+01],\n",
      "         [1.6545e-01, 3.0289e-01]],\n",
      "\n",
      "        [[1.2474e+00, 4.1059e-01],\n",
      "         [8.6614e-01, 6.6004e-01],\n",
      "         [2.1333e-04, 3.2342e-03],\n",
      "         ...,\n",
      "         [5.3671e-04, 7.6558e-01],\n",
      "         [2.8320e-01, 7.9927e-01],\n",
      "         [2.4081e-02, 2.9656e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.2458e-02, 1.1487e+00],\n",
      "         [4.0251e-03, 2.1648e-01],\n",
      "         [1.4447e-01, 9.2552e-01],\n",
      "         ...,\n",
      "         [2.9329e-02, 5.1358e-01],\n",
      "         [2.5156e-03, 5.9420e-04],\n",
      "         [1.1679e-01, 5.1431e-02]],\n",
      "\n",
      "        [[1.3921e+00, 1.7594e-01],\n",
      "         [7.4764e-02, 2.2647e-01],\n",
      "         [4.0569e-02, 1.8380e-03],\n",
      "         ...,\n",
      "         [1.8294e-01, 1.6684e-05],\n",
      "         [4.8575e-01, 1.9407e-02],\n",
      "         [3.5965e-01, 2.1655e+00]],\n",
      "\n",
      "        [[2.6098e-01, 1.5095e+00],\n",
      "         [2.6221e-01, 2.1763e+00],\n",
      "         [1.7448e-01, 9.3846e-01],\n",
      "         ...,\n",
      "         [4.2160e-01, 2.2330e+00],\n",
      "         [3.3385e-01, 4.3355e-02],\n",
      "         [1.3106e+00, 7.0380e-02]]])\n",
      "masked_square_error\n",
      "tensor([[[2.4633e-01, 9.2474e-02],\n",
      "         [4.0198e-02, 9.5143e-02],\n",
      "         [8.5194e-01, 5.9714e-02],\n",
      "         ...,\n",
      "         [2.6365e-02, 6.3627e-02],\n",
      "         [0.0000e+00, 0.0000e+00],\n",
      "         [1.9050e-01, 1.1751e+00]],\n",
      "\n",
      "        [[1.5283e-01, 1.2459e-03],\n",
      "         [2.5769e-01, 2.4223e-04],\n",
      "         [4.5663e-01, 3.0939e-01],\n",
      "         ...,\n",
      "         [2.6249e-01, 5.8232e-01],\n",
      "         [0.0000e+00, 0.0000e+00],\n",
      "         [1.6545e-01, 3.0289e-01]],\n",
      "\n",
      "        [[1.2474e+00, 4.1059e-01],\n",
      "         [8.6614e-01, 6.6004e-01],\n",
      "         [2.1333e-04, 3.2342e-03],\n",
      "         ...,\n",
      "         [5.3671e-04, 7.6558e-01],\n",
      "         [2.8320e-01, 7.9927e-01],\n",
      "         [2.4081e-02, 2.9656e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.2458e-02, 1.1487e+00],\n",
      "         [4.0251e-03, 2.1648e-01],\n",
      "         [1.4447e-01, 9.2552e-01],\n",
      "         ...,\n",
      "         [2.9329e-02, 5.1358e-01],\n",
      "         [2.5156e-03, 5.9420e-04],\n",
      "         [1.1679e-01, 5.1431e-02]],\n",
      "\n",
      "        [[1.3921e+00, 1.7594e-01],\n",
      "         [7.4764e-02, 2.2647e-01],\n",
      "         [4.0569e-02, 1.8380e-03],\n",
      "         ...,\n",
      "         [1.8294e-01, 1.6684e-05],\n",
      "         [4.8575e-01, 1.9407e-02],\n",
      "         [3.5965e-01, 2.1655e+00]],\n",
      "\n",
      "        [[2.6098e-01, 1.5095e+00],\n",
      "         [2.6221e-01, 2.1763e+00],\n",
      "         [1.7448e-01, 9.3846e-01],\n",
      "         ...,\n",
      "         [4.2160e-01, 2.2330e+00],\n",
      "         [3.3385e-01, 4.3355e-02],\n",
      "         [1.3106e+00, 7.0380e-02]]])\n",
      "tensor(0.8689)\n"
     ]
    }
   ],
   "source": [
    "for index, (image, joints, joint_transforms) in enumerate(train_loader):\n",
    "    flattened_joints = joints[:, :, :2].flatten(start_dim=1)\n",
    "    random_joints = torch.rand(flattened_joints.shape)\n",
    "    loss = masked_mse_loss(random_joints, joints)\n",
    "    print(loss)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
